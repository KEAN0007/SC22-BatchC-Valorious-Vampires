{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# The Task at Hand\n",
    "\n",
    "Have you ever wondered if computers could translate languages? Did you think google translate or duolingo worked because they memorized answers? \n",
    "\n",
    "The type of problem that translation solves is sequence to sequence. For instance, we could convert an english input sequence to a german output sequence. \n",
    "\n",
    "In this activity, we will create an english -> chinese translator and apply what we've been learning about LSTMs & RNNs.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Preparing the data\n",
    "We need to import our packages and data to learn a little bit about the problem at hand."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "id": "PS0kPzE04YFO"
   },
   "outputs": [
   ],
   "source": [
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "from nltk.tokenize import WordPunctTokenizer\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn.functional as F\n",
    "import pandas as pd\n",
    "import torch\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "from Word2Sequence import Word2Sequence\n",
    "from Dataset import Dataset\n",
    "from Seq2Seq import Seq2Seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
    "# read small_en-cn.txt file\n",
    "data_path = './eng-chin.txt'\n",
    "df = pd.read_table(data_path,header=None).iloc[:,:]\n",
    "df = df.drop([2],axis=1)\n",
    "df.columns=['english','chinese']\n",
    "\n",
    "input_texts = df.english.values.tolist() #this will be all of the english sentences\n",
    "target_texts = df.chinese.values.tolist() #this will be all of the chinese sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Does any other country fan the flames of patriotism as much as America?', 'I always enjoy listening to classical music when I have some free time.', 'I was nine years old when I asked my mom if Santa Claus really existed.', \"I'm a foreigner and I don't know Czech very well. Please, speak slowly.\", \"If it's at all possible, I'd like you to take part in the next meeting.\", 'If you enjoy the work you do, you have something worth more than money.', \"It was not until I had a baby myself that I knew what mother's love is.\", 'Kindness is the language which the deaf can hear and the blind can see.', 'Mary came home from school in tears because her friends had teased her.', 'My father was no less affectionate and tender to me than my mother was.', \"Now's the time to decide whether you really want to get married or not.\", 'People show up bright on an infrared camera because of their body heat.', 'The police have been searching for the stolen goods for almost a month.', 'They told me that I would feel a little better if I took this medicine.', \"Tom couldn't go to college because his family didn't have enough money.\", 'When his food supply ran short, he had to look for a new place to live.', 'While I was reading in bed last night, I fell asleep with the light on.', 'Where have you been? \"I have been to the station to see a friend off.\"', \"By the way, did you find the umbrella you said you'd lost the other day?\", 'Her eyes shone with joy when she saw that her mother was not mad at her.', 'I can place the palms of my hands on the floor without bending my knees.', \"I learned to drive a car and got a driver's license when I was eighteen.\", \"I learned to drive a car when I was eighteen and got a driver's license.\", 'I was planning on going to the beach today, but then it started to rain.', \"If we knew what we were doing, it wouldn't be called research, would it?\", \"If you want to go, then go. If you don't want to, then it's no big deal.\", 'In the U.S., most people can vote when they reach eighteen years of age.', 'It is the things that we do not possess which seem to us most desirable.', \"Rather than cutting down on cigarettes, why don't you just give them up?\", 'Sociopaths rarely display remorse or feelings of guilt for their crimes.', \"Tom can't account for his whereabouts on the day that Mary was murdered.\", 'Tom never forgets to give his wife flowers on their wedding anniversary.', 'Tom was able to make himself understood in French when he visited Paris.', \"We were talking about something at that time, but I don't remember what.\", \"You shouldn't share too much private information on the social networks.\", 'After Tom lost his job, he started to gamble to cope with his depression.', 'After school, I go to an English school to practice English conversation.', \"I think you'll have very little difficulty in getting a driver's license.\", 'I thought we had found the perfect hiding place, but the police found us.', \"I'd like to know the phone number of the nearest American Express office.\", 'She visits the dentist on a regular basis, so she seldom gets toothaches.', \"To make matters worse, he isn't even conscious of annoying his neighbors.\", 'You seem to be prejudiced against ideas that come from foreign countries.', 'If a sick person folds one thousand paper cranes, her wish will come true.', \"It's hard to believe that Tom wasn't aware that Mary was in love with him.\", 'Tom returned to his hometown to visit his parents during the summer break.', 'We must take into account the wishes of all the family in planning a trip.', \"You're much less likely to get a good position if you don't speak English.\", 'After asking for my key at the front desk, I took the elevator to my floor.', 'English has now become the common language of several nations in the world.', 'Outside the school, she saw people with no homes living in cardboard boxes.', \"The Prime Minister's speech was calculated to anger the opposition parties.\", \"The good thing about this electronic dictionary is that it's easy to carry.\", 'The lady really flipped out when she learned she had won a million dollars.', 'We apologize for the delay and regret any inconvenience it may have caused.', 'According to newspaper reports, there was an airplane accident last evening.', 'After he had graduated from the university, he taught English for two years.', 'If a man had 11 sheep and all but 9 died, how many sheep would he have left?', 'If it rains on that day, the game will be postponed until the next fine day.', \"It would take me too much time to explain to you why it's not going to work.\", 'The importation of rare wild animals to this country is strictly prohibited.', 'The statue of Hachiko, the faithful dog, stands in front of Shibuya Station.', 'A person views things differently according to whether they are rich or poor.', 'Although the government refuses to admit it, its economic policy is in ruins.', 'Mary tied an apron around her waist and then took the turkey out of the oven.', 'People look at things differently depending on whether they are rich or poor.', 'The population of London is much greater than that of any other British city.', \"They consider it impolite to disagree with someone they don't know very well.\", 'Three out of four Americans believe in the existence of paranormal phenomena.', \"Tom came to the conclusion that no matter what he did, Mary wouldn't like it.\", 'Eighty percent of all information on computers around the world is in English.', 'I thought that we had found the perfect hiding place, but the police found us.', \"I've had a scratchy throat since this morning. I wonder if I've caught a cold.\", \"If it looks like an apple and it tastes like an apple, it's probably an apple.\", 'The world is just like a book, and every step you take is like turning a page.', \"Today, I was supposed to study at the library but I woke up around 12 o'clock.\", 'Tom can write almost like a native speaker, but his pronunciation is terrible.', \"Tom did the best he could, but he wasn't able to get a higher grade than Mary.\", 'As the train came to a halt, all of the passengers wondered what was happening.', 'Charles Lindbergh made the first solo flight across the Atlantic Ocean in 1927.', \"His scores are always better than mine, even though he doesn't study very much.\", \"I don't have a lot of work, but it's enough to keep me in the office this week.\", 'I returned the books I borrowed from the library, and I borrowed some new ones.', \"Publication of the article was timed to coincide with the professor's birthday.\", \"She's popular, not because she's beautiful, but because she's kind to everyone.\", 'The telephone operator asked the caller to hold on until a connection was made.', \"Whoever said money can't buy happiness simply didn't know where to go shopping.\", 'At the time there were no native English speakers teaching in any public school.', 'Rio de Janeiro is perfectly safe as long as you stay out of the dangerous areas.', 'She was asked to convince him to get his son or someone else to paint the house.', 'Tom always speaks in such a low voice that I can barely understand what he says.', \"Even though I studied English for 6 years in school, I'm not good at speaking it.\", 'I bought a second badminton racket for myself, but I forgot to buy a shuttlecock.', \"I didn't know the city, and what's more, I couldn't speak a word of the language.\", 'The ages of the two children put together was equivalent to that of their father.', 'To the man who only has a hammer in the toolkit, every problem looks like a nail.', 'Tom went swimming in the river, but when he got out, his clothes had been stolen.', 'Being a good conversationalist does not just mean being a good speaker of English.', \"Manholes are round because that way they won't accidentally fall through the hole.\"]\n",
      "['有没有一个国家比美国更提倡爱国主义？', '有空的时候，我总喜欢听古典音乐。', '我九岁的时候问我妈妈圣诞老人是否真的存在。', '我是外国人，我捷克语不好，请说慢一点。', '如果可能的話, 我希望你參加下一次的會議。', '如果你喜歡你做的工作，你就有比金錢更有價值的東西。', '直到我自己有了孩子我才明白了什么是母爱。', '善良是聾子能聽盲人能看的語言。', '玛丽哭着从学校跑回了家里，因为她的朋友捉弄了她。', '我爸爸对我的爱和照顾不比我妈妈少。', '现在是你决定是不是真要结婚的时候。', '人會因為體溫而在紅外線攝影機上顯現。', '警察大概从一个月前就开始找被偷物品了。', '他們告訴我吃完這個藥我就會覺得舒服一點。', '因为家里钱不够所以汤姆没能念大学。', '他的食物供给不足的的时候，他不得不去找新的地方居住。', '我昨晚在床上看书的时候点着灯就睡了。', '“你去哪儿了？”“我去了火车站送我的一个朋友。”', '对了，前些时间你说伞不见了，现在找到了吗？', '當她看到媽媽沒在生她的氣，她的雙眼因為幸福而閃爍了。', '我不用曲膝就能把我的手掌放到地上。', '我十八歲時，學了開車、考到了駕照。', '我十八歲時，學了開車、考到了駕照。', '我本来预备今天去海滩的，但接着天就开始下雨了。', '如果我们知道我们在做什么，那么这不能称之为研究，是吗？', '如果你想去，就去好了。如果你不想去，那也没什么大不了的。', '在美国，大多数人能在十八岁后投票选举。', '得不到的东西就最想得到。', '比起少抽菸，你何不直接把菸戒了？', '反社会者极少为他们的罪行显露懊悔或有罪恶的感觉。', '汤姆不能说明玛丽遇害那天自己在哪里。', '汤姆从没忘记在婚礼周年纪念日送给他妻子花。', '在巴黎，沒有人能夠理解湯姆的法文。', '我们那时在谈论事情，但我不记得是什么了。', '你不应该在社交网络上分享过多私人信息。', '湯姆失業後，為了排遣鬱悶的心情而開始了賭博。', '放學後，我到一所英語學校去練習英語會話。', '我想你要拿到驾照根本不难。', '我以为我们发现了绝妙的藏身之处，但警察找到了我们。', '我想知道最近的美國運通辦事處的電話號碼。', '她定期去看牙医，所以她很少牙痛。', '让事情更糟糕的是，他没有注意到他打扰到了邻居。', '你似乎對來自國外的想法有偏見。', '如果一個病人折一千隻紙鶴, 她的願望就會成真。', '真难相信汤姆不知道玛丽爱他。', '汤姆在夏休回乡看望父母。', '筹划旅行的时候，我们必须考虑到全家人的意愿。', '如果你不会说英语，你就很难得到一个好的职位。', '我到櫃檯拿了鑰匙，然後就乘電梯去了我房間的樓層。', '英语现已成为世界上许多国家的通用语言了。', '在校外，她见到没有家的人们住在纸板箱里。', '總理的發言估計激怒了在野黨。', '这电子辞典的好处就是便于携带。', '當這位女士得知她已經贏得了百萬美元, 她真的樂瘋了。', '我们对这次的延迟表示抱歉，并对可能造成的不便表示遗憾。', '根據報載，有一架飛機昨天晚上發生了意外。', '從他大學畢業以後, 他教了兩年的英語。', '如果一个人有11只羊，除了9只之外，其他全部死了，那么他还剩下几只羊呢？', '如果那天下雨，比赛会顺延至下一个晴天。', '给你解释这为什么行不通要花很多时间。', '该国严禁进口稀有野生动物。', '忠犬八公的雕像伫立在涩谷站前。', '每一個人對事情的看法不同是依據他們是富有還是貧窮。', '尽管政府拒绝承认，它的经济政策还是失败了。', 'Mary试图把围裙围在腰上，然后把烤鸡从炉子里拿出来。', '人們看待事情的角度不同取決於他們是富裕或貧窮。', '倫敦的人口遠遠多於其他英國城市的人口。', '他们认为，去反驳一个不认识的人有些不礼貌。', '四分之三的美国人相信存在超自然现象。', '汤姆得出无论他做什么，玛丽都不会喜欢的结论。', '全世界百分之八十電腦上的資訊都是用英語寫的。', '我以为我们发现了绝妙的藏身之处，但警察找到了我们。', '早上起来，嗓子变得很沙哑，我想是不是感冒了。', '如果看起来像个苹果而且吃起来也像苹果的话，可能就是苹果。', '世界就像是一本书，走一步等于翻了一页。', '今天，我本打算在图书馆学习但到12点左右才醒。', 'Tom写作可以写的像本国人一样，可是他的发音很烂', '汤姆尽了全力，但他还是不能获得比玛丽更高的等级。', '当列车停止时，所有的乘客都想知道发生了什么。', 'Charles Lindbergh於1927年成功完成了第一次獨自飛越大西洋。', '他的分数总比我高，尽管他学习得少一点。', '其实我工作并不多，但足以让我这周在办公室里忙着了。', '我还了从图书馆借的书，又借了些新的。', '文章的发表被预定在教授生日那天。', '她受歡迎不是因為她的美麗，而是因為她親切地對待每個人。', '电话运营商提示来电人等候接通。', '那些说钱不能买来幸福的人，只是不知道上哪里去买而已。', '當時沒有任何以英語為母語的人在公立學校任教。', '如果你远离危险区域，里约热内卢就是完全安全的。', '她被要求去说服他以让他或者他的儿子或者是别的人来粉刷屋子。', '汤姆总是说话声音太小，我几乎听不懂他在说什么。', '尽管我在学校学了6年英语，我还是说不好。', '我为自己买了副羽毛球拍，但我忘记买羽毛球了。', '我不知道这个城市，而且我一点都不懂那里的语言。', '两个孩子的年龄加起来和他们的父亲相当。', '对工具箱里只有一把榔头的人来说，所有的问题都像钉子。', '汤姆去河里游泳，但当他出来时，他的衣服被偷了。', '作為一個良好的交談者，並不只意味著作一個英語說得好的說話者。', '人孔是圓的，因為這樣人孔蓋就不會意外地掉進洞裡。']\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Your code here: Try printing some english and chinese sentences from their lists input_texts and target_texts!\n",
    "'''\n",
    "print(input_texts)\n",
    "print(target_texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "id": "cPXhq9PO4dOC"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['does', 'any', 'other', 'country', 'fan', 'the', 'flames', 'of', 'patriotism', 'as', 'much', 'as', 'america', '?'], ['i', 'always', 'enjoy', 'listening', 'to', 'classical', 'music', 'when', 'i', 'have', 'some', 'free', 'time', '.'], ['i', 'was', 'nine', 'years', 'old', 'when', 'i', 'asked', 'my', 'mom', 'if', 'santa', 'claus', 'really', 'existed', '.'], ['i', \"'\", 'm', 'a', 'foreigner', 'and', 'i', 'don', \"'\", 't', 'know', 'czech', 'very', 'well', '.', 'please', ',', 'speak', 'slowly', '.'], ['if', 'it', \"'\", 's', 'at', 'all', 'possible', ',', 'i', \"'\", 'd', 'like', 'you', 'to', 'take', 'part', 'in', 'the', 'next', 'meeting', '.'], ['if', 'you', 'enjoy', 'the', 'work', 'you', 'do', ',', 'you', 'have', 'something', 'worth', 'more', 'than', 'money', '.'], ['it', 'was', 'not', 'until', 'i', 'had', 'a', 'baby', 'myself', 'that', 'i', 'knew', 'what', 'mother', \"'\", 's', 'love', 'is', '.'], ['kindness', 'is', 'the', 'language', 'which', 'the', 'deaf', 'can', 'hear', 'and', 'the', 'blind', 'can', 'see', '.'], ['mary', 'came', 'home', 'from', 'school', 'in', 'tears', 'because', 'her', 'friends', 'had', 'teased', 'her', '.'], ['my', 'father', 'was', 'no', 'less', 'affectionate', 'and', 'tender', 'to', 'me', 'than', 'my', 'mother', 'was', '.'], ['now', \"'\", 's', 'the', 'time', 'to', 'decide', 'whether', 'you', 'really', 'want', 'to', 'get', 'married', 'or', 'not', '.'], ['people', 'show', 'up', 'bright', 'on', 'an', 'infrared', 'camera', 'because', 'of', 'their', 'body', 'heat', '.'], ['the', 'police', 'have', 'been', 'searching', 'for', 'the', 'stolen', 'goods', 'for', 'almost', 'a', 'month', '.'], ['they', 'told', 'me', 'that', 'i', 'would', 'feel', 'a', 'little', 'better', 'if', 'i', 'took', 'this', 'medicine', '.'], ['tom', 'couldn', \"'\", 't', 'go', 'to', 'college', 'because', 'his', 'family', 'didn', \"'\", 't', 'have', 'enough', 'money', '.'], ['when', 'his', 'food', 'supply', 'ran', 'short', ',', 'he', 'had', 'to', 'look', 'for', 'a', 'new', 'place', 'to', 'live', '.'], ['while', 'i', 'was', 'reading', 'in', 'bed', 'last', 'night', ',', 'i', 'fell', 'asleep', 'with', 'the', 'light', 'on', '.'], ['where', 'have', 'you', 'been', '?', '\"', 'i', 'have', 'been', 'to', 'the', 'station', 'to', 'see', 'a', 'friend', 'off', '.\"'], ['by', 'the', 'way', ',', 'did', 'you', 'find', 'the', 'umbrella', 'you', 'said', 'you', \"'\", 'd', 'lost', 'the', 'other', 'day', '?'], ['her', 'eyes', 'shone', 'with', 'joy', 'when', 'she', 'saw', 'that', 'her', 'mother', 'was', 'not', 'mad', 'at', 'her', '.'], ['i', 'can', 'place', 'the', 'palms', 'of', 'my', 'hands', 'on', 'the', 'floor', 'without', 'bending', 'my', 'knees', '.'], ['i', 'learned', 'to', 'drive', 'a', 'car', 'and', 'got', 'a', 'driver', \"'\", 's', 'license', 'when', 'i', 'was', 'eighteen', '.'], ['i', 'learned', 'to', 'drive', 'a', 'car', 'when', 'i', 'was', 'eighteen', 'and', 'got', 'a', 'driver', \"'\", 's', 'license', '.'], ['i', 'was', 'planning', 'on', 'going', 'to', 'the', 'beach', 'today', ',', 'but', 'then', 'it', 'started', 'to', 'rain', '.'], ['if', 'we', 'knew', 'what', 'we', 'were', 'doing', ',', 'it', 'wouldn', \"'\", 't', 'be', 'called', 'research', ',', 'would', 'it', '?'], ['if', 'you', 'want', 'to', 'go', ',', 'then', 'go', '.', 'if', 'you', 'don', \"'\", 't', 'want', 'to', ',', 'then', 'it', \"'\", 's', 'no', 'big', 'deal', '.'], ['in', 'the', 'u', '.', 's', '.,', 'most', 'people', 'can', 'vote', 'when', 'they', 'reach', 'eighteen', 'years', 'of', 'age', '.'], ['it', 'is', 'the', 'things', 'that', 'we', 'do', 'not', 'possess', 'which', 'seem', 'to', 'us', 'most', 'desirable', '.'], ['rather', 'than', 'cutting', 'down', 'on', 'cigarettes', ',', 'why', 'don', \"'\", 't', 'you', 'just', 'give', 'them', 'up', '?'], ['sociopaths', 'rarely', 'display', 'remorse', 'or', 'feelings', 'of', 'guilt', 'for', 'their', 'crimes', '.'], ['tom', 'can', \"'\", 't', 'account', 'for', 'his', 'whereabouts', 'on', 'the', 'day', 'that', 'mary', 'was', 'murdered', '.'], ['tom', 'never', 'forgets', 'to', 'give', 'his', 'wife', 'flowers', 'on', 'their', 'wedding', 'anniversary', '.'], ['tom', 'was', 'able', 'to', 'make', 'himself', 'understood', 'in', 'french', 'when', 'he', 'visited', 'paris', '.'], ['we', 'were', 'talking', 'about', 'something', 'at', 'that', 'time', ',', 'but', 'i', 'don', \"'\", 't', 'remember', 'what', '.'], ['you', 'shouldn', \"'\", 't', 'share', 'too', 'much', 'private', 'information', 'on', 'the', 'social', 'networks', '.'], ['after', 'tom', 'lost', 'his', 'job', ',', 'he', 'started', 'to', 'gamble', 'to', 'cope', 'with', 'his', 'depression', '.'], ['after', 'school', ',', 'i', 'go', 'to', 'an', 'english', 'school', 'to', 'practice', 'english', 'conversation', '.'], ['i', 'think', 'you', \"'\", 'll', 'have', 'very', 'little', 'difficulty', 'in', 'getting', 'a', 'driver', \"'\", 's', 'license', '.'], ['i', 'thought', 'we', 'had', 'found', 'the', 'perfect', 'hiding', 'place', ',', 'but', 'the', 'police', 'found', 'us', '.'], ['i', \"'\", 'd', 'like', 'to', 'know', 'the', 'phone', 'number', 'of', 'the', 'nearest', 'american', 'express', 'office', '.'], ['she', 'visits', 'the', 'dentist', 'on', 'a', 'regular', 'basis', ',', 'so', 'she', 'seldom', 'gets', 'toothaches', '.'], ['to', 'make', 'matters', 'worse', ',', 'he', 'isn', \"'\", 't', 'even', 'conscious', 'of', 'annoying', 'his', 'neighbors', '.'], ['you', 'seem', 'to', 'be', 'prejudiced', 'against', 'ideas', 'that', 'come', 'from', 'foreign', 'countries', '.'], ['if', 'a', 'sick', 'person', 'folds', 'one', 'thousand', 'paper', 'cranes', ',', 'her', 'wish', 'will', 'come', 'true', '.'], ['it', \"'\", 's', 'hard', 'to', 'believe', 'that', 'tom', 'wasn', \"'\", 't', 'aware', 'that', 'mary', 'was', 'in', 'love', 'with', 'him', '.'], ['tom', 'returned', 'to', 'his', 'hometown', 'to', 'visit', 'his', 'parents', 'during', 'the', 'summer', 'break', '.'], ['we', 'must', 'take', 'into', 'account', 'the', 'wishes', 'of', 'all', 'the', 'family', 'in', 'planning', 'a', 'trip', '.'], ['you', \"'\", 're', 'much', 'less', 'likely', 'to', 'get', 'a', 'good', 'position', 'if', 'you', 'don', \"'\", 't', 'speak', 'english', '.'], ['after', 'asking', 'for', 'my', 'key', 'at', 'the', 'front', 'desk', ',', 'i', 'took', 'the', 'elevator', 'to', 'my', 'floor', '.'], ['english', 'has', 'now', 'become', 'the', 'common', 'language', 'of', 'several', 'nations', 'in', 'the', 'world', '.'], ['outside', 'the', 'school', ',', 'she', 'saw', 'people', 'with', 'no', 'homes', 'living', 'in', 'cardboard', 'boxes', '.'], ['the', 'prime', 'minister', \"'\", 's', 'speech', 'was', 'calculated', 'to', 'anger', 'the', 'opposition', 'parties', '.'], ['the', 'good', 'thing', 'about', 'this', 'electronic', 'dictionary', 'is', 'that', 'it', \"'\", 's', 'easy', 'to', 'carry', '.'], ['the', 'lady', 'really', 'flipped', 'out', 'when', 'she', 'learned', 'she', 'had', 'won', 'a', 'million', 'dollars', '.'], ['we', 'apologize', 'for', 'the', 'delay', 'and', 'regret', 'any', 'inconvenience', 'it', 'may', 'have', 'caused', '.'], ['according', 'to', 'newspaper', 'reports', ',', 'there', 'was', 'an', 'airplane', 'accident', 'last', 'evening', '.'], ['after', 'he', 'had', 'graduated', 'from', 'the', 'university', ',', 'he', 'taught', 'english', 'for', 'two', 'years', '.'], ['if', 'a', 'man', 'had', '11', 'sheep', 'and', 'all', 'but', '9', 'died', ',', 'how', 'many', 'sheep', 'would', 'he', 'have', 'left', '?'], ['if', 'it', 'rains', 'on', 'that', 'day', ',', 'the', 'game', 'will', 'be', 'postponed', 'until', 'the', 'next', 'fine', 'day', '.'], ['it', 'would', 'take', 'me', 'too', 'much', 'time', 'to', 'explain', 'to', 'you', 'why', 'it', \"'\", 's', 'not', 'going', 'to', 'work', '.'], ['the', 'importation', 'of', 'rare', 'wild', 'animals', 'to', 'this', 'country', 'is', 'strictly', 'prohibited', '.'], ['the', 'statue', 'of', 'hachiko', ',', 'the', 'faithful', 'dog', ',', 'stands', 'in', 'front', 'of', 'shibuya', 'station', '.'], ['a', 'person', 'views', 'things', 'differently', 'according', 'to', 'whether', 'they', 'are', 'rich', 'or', 'poor', '.'], ['although', 'the', 'government', 'refuses', 'to', 'admit', 'it', ',', 'its', 'economic', 'policy', 'is', 'in', 'ruins', '.'], ['mary', 'tied', 'an', 'apron', 'around', 'her', 'waist', 'and', 'then', 'took', 'the', 'turkey', 'out', 'of', 'the', 'oven', '.'], ['people', 'look', 'at', 'things', 'differently', 'depending', 'on', 'whether', 'they', 'are', 'rich', 'or', 'poor', '.'], ['the', 'population', 'of', 'london', 'is', 'much', 'greater', 'than', 'that', 'of', 'any', 'other', 'british', 'city', '.'], ['they', 'consider', 'it', 'impolite', 'to', 'disagree', 'with', 'someone', 'they', 'don', \"'\", 't', 'know', 'very', 'well', '.'], ['three', 'out', 'of', 'four', 'americans', 'believe', 'in', 'the', 'existence', 'of', 'paranormal', 'phenomena', '.'], ['tom', 'came', 'to', 'the', 'conclusion', 'that', 'no', 'matter', 'what', 'he', 'did', ',', 'mary', 'wouldn', \"'\", 't', 'like', 'it', '.'], ['eighty', 'percent', 'of', 'all', 'information', 'on', 'computers', 'around', 'the', 'world', 'is', 'in', 'english', '.'], ['i', 'thought', 'that', 'we', 'had', 'found', 'the', 'perfect', 'hiding', 'place', ',', 'but', 'the', 'police', 'found', 'us', '.'], ['i', \"'\", 've', 'had', 'a', 'scratchy', 'throat', 'since', 'this', 'morning', '.', 'i', 'wonder', 'if', 'i', \"'\", 've', 'caught', 'a', 'cold', '.'], ['if', 'it', 'looks', 'like', 'an', 'apple', 'and', 'it', 'tastes', 'like', 'an', 'apple', ',', 'it', \"'\", 's', 'probably', 'an', 'apple', '.'], ['the', 'world', 'is', 'just', 'like', 'a', 'book', ',', 'and', 'every', 'step', 'you', 'take', 'is', 'like', 'turning', 'a', 'page', '.'], ['today', ',', 'i', 'was', 'supposed', 'to', 'study', 'at', 'the', 'library', 'but', 'i', 'woke', 'up', 'around', '12', 'o', \"'\", 'clock', '.'], ['tom', 'can', 'write', 'almost', 'like', 'a', 'native', 'speaker', ',', 'but', 'his', 'pronunciation', 'is', 'terrible', '.'], ['tom', 'did', 'the', 'best', 'he', 'could', ',', 'but', 'he', 'wasn', \"'\", 't', 'able', 'to', 'get', 'a', 'higher', 'grade', 'than', 'mary', '.'], ['as', 'the', 'train', 'came', 'to', 'a', 'halt', ',', 'all', 'of', 'the', 'passengers', 'wondered', 'what', 'was', 'happening', '.'], ['charles', 'lindbergh', 'made', 'the', 'first', 'solo', 'flight', 'across', 'the', 'atlantic', 'ocean', 'in', '1927', '.'], ['his', 'scores', 'are', 'always', 'better', 'than', 'mine', ',', 'even', 'though', 'he', 'doesn', \"'\", 't', 'study', 'very', 'much', '.'], ['i', 'don', \"'\", 't', 'have', 'a', 'lot', 'of', 'work', ',', 'but', 'it', \"'\", 's', 'enough', 'to', 'keep', 'me', 'in', 'the', 'office', 'this', 'week', '.'], ['i', 'returned', 'the', 'books', 'i', 'borrowed', 'from', 'the', 'library', ',', 'and', 'i', 'borrowed', 'some', 'new', 'ones', '.'], ['publication', 'of', 'the', 'article', 'was', 'timed', 'to', 'coincide', 'with', 'the', 'professor', \"'\", 's', 'birthday', '.'], ['she', \"'\", 's', 'popular', ',', 'not', 'because', 'she', \"'\", 's', 'beautiful', ',', 'but', 'because', 'she', \"'\", 's', 'kind', 'to', 'everyone', '.'], ['the', 'telephone', 'operator', 'asked', 'the', 'caller', 'to', 'hold', 'on', 'until', 'a', 'connection', 'was', 'made', '.'], ['whoever', 'said', 'money', 'can', \"'\", 't', 'buy', 'happiness', 'simply', 'didn', \"'\", 't', 'know', 'where', 'to', 'go', 'shopping', '.'], ['at', 'the', 'time', 'there', 'were', 'no', 'native', 'english', 'speakers', 'teaching', 'in', 'any', 'public', 'school', '.'], ['rio', 'de', 'janeiro', 'is', 'perfectly', 'safe', 'as', 'long', 'as', 'you', 'stay', 'out', 'of', 'the', 'dangerous', 'areas', '.'], ['she', 'was', 'asked', 'to', 'convince', 'him', 'to', 'get', 'his', 'son', 'or', 'someone', 'else', 'to', 'paint', 'the', 'house', '.'], ['tom', 'always', 'speaks', 'in', 'such', 'a', 'low', 'voice', 'that', 'i', 'can', 'barely', 'understand', 'what', 'he', 'says', '.'], ['even', 'though', 'i', 'studied', 'english', 'for', '6', 'years', 'in', 'school', ',', 'i', \"'\", 'm', 'not', 'good', 'at', 'speaking', 'it', '.'], ['i', 'bought', 'a', 'second', 'badminton', 'racket', 'for', 'myself', ',', 'but', 'i', 'forgot', 'to', 'buy', 'a', 'shuttlecock', '.'], ['i', 'didn', \"'\", 't', 'know', 'the', 'city', ',', 'and', 'what', \"'\", 's', 'more', ',', 'i', 'couldn', \"'\", 't', 'speak', 'a', 'word', 'of', 'the', 'language', '.'], ['the', 'ages', 'of', 'the', 'two', 'children', 'put', 'together', 'was', 'equivalent', 'to', 'that', 'of', 'their', 'father', '.'], ['to', 'the', 'man', 'who', 'only', 'has', 'a', 'hammer', 'in', 'the', 'toolkit', ',', 'every', 'problem', 'looks', 'like', 'a', 'nail', '.'], ['tom', 'went', 'swimming', 'in', 'the', 'river', ',', 'but', 'when', 'he', 'got', 'out', ',', 'his', 'clothes', 'had', 'been', 'stolen', '.'], ['being', 'a', 'good', 'conversationalist', 'does', 'not', 'just', 'mean', 'being', 'a', 'good', 'speaker', 'of', 'english', '.'], ['manholes', 'are', 'round', 'because', 'that', 'way', 'they', 'won', \"'\", 't', 'accidentally', 'fall', 'through', 'the', 'hole', '.']]\n"
     ]
    }
   ],
   "source": [
    "#read in our model object. Tokenize our data\n",
    "tk = WordPunctTokenizer()\n",
    "english = [tk.tokenize(sentence.lower()) for sentence in input_texts]\n",
    "chinese = [[x for x in sentence] for sentence in target_texts]\n",
    "\n",
    "print(english)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25\n",
      "39\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Your code here: Explore this data. Can you calculate the maximum length of a sequence in each dataset english and chinese?\n",
    "'''\n",
    "# calculate max_len of any sequence in 'english' list and save it to a variable called max_english_length\n",
    "\n",
    "max_english_length = 0\n",
    "\n",
    "for sentence in english:\n",
    "    maxlenold = len(sentence)\n",
    "    if maxlenold > max_english_length:\n",
    "        max_english_length = maxlenold\n",
    "    #print(maxlen)\n",
    "print(max_english_length)\n",
    "\n",
    "\n",
    "# calculate max_len of any sequence in 'chinese' list and save it to a variable called max_chinese_length\n",
    "\n",
    "max_chinese_length = 0\n",
    "\n",
    "for sentence in chinese:\n",
    "    maxlcnold = len(sentence)\n",
    "    if maxlcnold > max_chinese_length:\n",
    "        max_chinese_length = maxlcnold\n",
    "    #print(maxlen)\n",
    "print(max_chinese_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": false,
    "id": "ZzoUqCrq4fWj",
    "outputId": "4290ee15-457e-44d7-f083-f12a2e5d78a2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "199\n",
      "317\n"
     ]
    }
   ],
   "source": [
    "input_tokenizer = Word2Sequence()\n",
    "for words in english:\n",
    "    input_tokenizer.fit(words)\n",
    "input_tokenizer.build_vocab(min=1, max_features=None) #input\n",
    "\n",
    "output_tokenizer = Word2Sequence()\n",
    "for words in chinese:\n",
    "    output_tokenizer.fit(words)\n",
    "output_tokenizer.build_vocab(min=1, max_features=None)\n",
    "\n",
    "'''\n",
    "Your code here: print the total english words in your input tokenizer and total chinese words in your output tokenizer below!\n",
    "'''\n",
    "print(input_tokenizer.__len__())\n",
    "\n",
    "print(output_tokenizer.__len__())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "<h1>Creating the model</h1>\n",
    "\n",
    "![image.png](data:image/png;base64,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)\n",
    "\n",
    "NOTE: For Structure of Encoder Inputs, they can all be either (assume all have same maxlen): \n",
    "\n",
    "1. \\<SOS>, word1, word2, word3, ..., \\<EOS>\n",
    "2. word1, word2, word3, ..., \\<EOS> \n",
    "3. word1, word2, word3, ...\n",
    "\n",
    "NOTE: But Decoder In and Out structures should always look like this (assume all have same maxlen):\n",
    "\n",
    "- Decoder Input: \\<SOS>, word1, word2, word3, ...\n",
    "- Decoder Output: word1, word2, word3, ..., \\<EOS>  \n",
    "\n",
    "This means that our input and ouput max length should be one more than the sequence's max length.\n",
    "\n",
    "WHY? Data Structure:\n",
    "\n",
    "- 1. Encoder Input: [word1, word2, ... + <EOS>]\n",
    "- 2. Decoder Input: [<SOS> + word1, word2, ...]\n",
    "- 3. Decoder Output:[word1, word2, ... + <EOS>]\n",
    "    \n",
    "\n",
    "nn docs - https://pytorch.org/docs/stable/nn.html\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false,
    "id": "qm_Qhnlk49Rn"
   },
   "outputs": [
   ],
   "source": [
    "# Seq2Seq Parameters\n",
    "in_maxlen = max_english_length + 1 # 25 + 1(<EOS> token)\n",
    "out_maxlen = max_chinese_length + 1 # 39 + 1(<EOS> token or <SOS> token)\n",
    "n_hidden = 32 # number of \"neurons\" per layer\n",
    "d_model = 64 # number of embedding dimensions to represent each word\n",
    "enc_n_class = len(input_tokenizer.dict) # OR... vocab size of englisth -> 199\n",
    "dec_n_class = len(output_tokenizer.dict) # OR... vocab size of chinese -> 317\n",
    "batch_size = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
    "eng_maxlen = max_english_length + 1 # 25 + 1(<EOS> token)\n",
    "chin_maxlen = max_chinese_length + 1  # 39 + 1(<EOS> token or <SOS> token)\n",
    "batch_size = 1\n",
    "\n",
    "# Setup the Dataset.\n",
    "dataset = Dataset(\n",
    "    X = english,\n",
    "    Y = chinese,\n",
    "    in_tknz = input_tokenizer, out_tknz = output_tokenizer,\n",
    "    in_maxlen = eng_maxlen, out_maxlen = chin_maxlen\n",
    ")\n",
    "\n",
    "'''\n",
    "The following are helper functions to help pytorch. You won't need to know this much.\n",
    "'''\n",
    "# NOTE: collate_fn preprocesses your input from PyTorch Dataset above during PyTorch DataLoader\n",
    "def collate_fn(batch):\n",
    "    '''\n",
    "    param batch: ([enc_in, dec_in, dec_out]， [enc_in, dec_in, dec_out], output of getitem...)\n",
    "    '''\n",
    "    # unpack values\n",
    "    enc_in, dec_in, dec_out = list(zip(*batch))\n",
    "    # Return tensor type\n",
    "    return torch.LongTensor(enc_in), torch.LongTensor(dec_in), torch.LongTensor(dec_out)\n",
    "\n",
    "def get_dataloader(dataset, batch_size, shuffle=True, drop_last=True, collate_fn=collate_fn):\n",
    "    '''\n",
    "    Returns a way to access and use the data\n",
    "    '''\n",
    "    dataloader = DataLoader(dataset=dataset,\n",
    "                            batch_size=batch_size,\n",
    "                            shuffle=shuffle,\n",
    "                            drop_last=drop_last,\n",
    "                            collate_fn=collate_fn)\n",
    "    return dataloader\n",
    "# Get PyTorch DataLoader\n",
    "dataloader = get_dataloader(dataset, batch_size)\n",
    "dataloader = get_dataloader(dataset, batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": false,
    "id": "oVVbVP7l5AJg",
    "outputId": "e28da9fa-5fa2-4fbd-b4d3-49de9999475b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Seq2Seq(\n",
       "  (encoder): GRU(64, 32, dropout=0.3)\n",
       "  (decoder): GRU(64, 32, dropout=0.3)\n",
       "  (embed_enc): Embedding(199, 64)\n",
       "  (embed_dec): Embedding(317, 64)\n",
       "  (fc): Linear(in_features=32, out_features=317, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 59,
     "metadata": {
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Seq2Seq(\n",
    "    in_maxlen = in_maxlen,\n",
    "    out_maxlen = out_maxlen,\n",
    "    n_hidden = n_hidden,\n",
    "    enc_n_class = len(input_tokenizer.dict),\n",
    "    dec_n_class = len(output_tokenizer.dict),\n",
    "    d_model = d_model,\n",
    "    num_layers = 1,\n",
    ")\n",
    "model.to(device)\n",
    "# # If you have saved a model before\n",
    "# model.load_state_dict(torch.load(\"seq2seq.pt\", map_location=device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false,
    "id": "PtNvjmBo5A8W"
   },
   "outputs": [
   ],
   "source": [
    "# Define Loss and Optimizer -- these are ways we define performance for our model. If you're curious: https://pytorch.org/tutorials/beginner/basics/optimization_tutorial.html\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optim = torch.optim.Adam(model.parameters(), lr=1e-2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "id": "wVpmLnAtBLEV"
   },
   "source": [
    "<h1>tRaInInG oUr MoDeL</h1>\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": false,
    "id": "PTSlF8fk5QpG",
    "outputId": "3eb0df28-80b9-452b-e9b5-5c7ffff27c98",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, Loss: 575.5717163085938\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1, Loss: 519.2578125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2, Loss: 475.4347839355469\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 3, Loss: 442.1078796386719\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 4, Loss: 413.8287048339844\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 5, Loss: 386.9122619628906\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 6, Loss: 360.6662292480469\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 7, Loss: 336.0145263671875\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 8, Loss: 314.1577453613281\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 9, Loss: 295.8831481933594\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 10, Loss: 281.384765625\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 11, Loss: 270.3678894042969\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 12, Loss: 262.24462890625\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 13, Loss: 256.3305969238281\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 14, Loss: 251.9749298095703\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 15, Loss: 248.62973022460938\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 16, Loss: 245.85562133789062\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 17, Loss: 243.30599975585938\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 18, Loss: 240.78565979003906\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 19, Loss: 238.3236083984375\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 20, Loss: 236.02650451660156\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 21, Loss: 233.90499877929688\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 22, Loss: 231.9191131591797\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 23, Loss: 229.98716735839844\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 24, Loss: 228.03741455078125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 25, Loss: 226.041015625\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 26, Loss: 223.97512817382812\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 27, Loss: 221.85195922851562\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 28, Loss: 219.71035766601562\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 29, Loss: 217.58596801757812\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 30, Loss: 215.4944610595703\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 31, Loss: 213.42852783203125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 32, Loss: 211.36378479003906\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 33, Loss: 209.27037048339844\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 34, Loss: 207.1254425048828\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 35, Loss: 204.92007446289062\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 36, Loss: 202.6622314453125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 37, Loss: 200.36959838867188\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 38, Loss: 198.0574188232422\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 39, Loss: 195.74119567871094\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 40, Loss: 193.4237060546875\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 41, Loss: 191.09950256347656\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 42, Loss: 188.76351928710938\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 43, Loss: 186.4110870361328\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 44, Loss: 184.03759765625\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 45, Loss: 181.64393615722656\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 46, Loss: 179.23336791992188\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 47, Loss: 176.8151092529297\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 48, Loss: 174.39688110351562\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 49, Loss: 171.9832763671875\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 50, Loss: 169.5782012939453\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 51, Loss: 167.19041442871094\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 52, Loss: 164.81285095214844\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 53, Loss: 162.4415740966797\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 54, Loss: 160.08251953125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 55, Loss: 157.74403381347656\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 56, Loss: 155.42868041992188\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 57, Loss: 153.12832641601562\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 58, Loss: 150.83935546875\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 59, Loss: 148.569091796875\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 60, Loss: 146.3199462890625\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 61, Loss: 144.08641052246094\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 62, Loss: 141.86972045898438\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 63, Loss: 139.67709350585938\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 64, Loss: 137.50840759277344\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 65, Loss: 135.35995483398438\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 66, Loss: 133.23233032226562\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 67, Loss: 131.13307189941406\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 68, Loss: 129.06370544433594\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 69, Loss: 127.01480865478516\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 70, Loss: 124.98944854736328\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 71, Loss: 122.98826599121094\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 72, Loss: 121.00604248046875\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 73, Loss: 119.0541763305664\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 74, Loss: 117.13282775878906\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 75, Loss: 115.23896026611328\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 76, Loss: 113.37016296386719\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 77, Loss: 111.5250473022461\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 78, Loss: 109.70712280273438\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 79, Loss: 107.91398620605469\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 80, Loss: 106.1516342163086\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 81, Loss: 104.4078369140625\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 82, Loss: 102.68170166015625\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 83, Loss: 100.97583770751953\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 84, Loss: 99.29212188720703\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 85, Loss: 97.62538146972656\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 86, Loss: 95.98739624023438\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 87, Loss: 94.38090515136719\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 88, Loss: 92.78578186035156\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 89, Loss: 91.21329498291016\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 90, Loss: 89.6609878540039\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 91, Loss: 88.12102508544922\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 92, Loss: 86.60914611816406\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 93, Loss: 85.117431640625\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 94, Loss: 83.66741943359375\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 95, Loss: 82.22160339355469\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 96, Loss: 80.80804443359375\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 97, Loss: 79.39954376220703\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 98, Loss: 78.0044937133789\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 99, Loss: 76.65457153320312\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 100, Loss: 75.30638122558594\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 101, Loss: 73.95574188232422\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 102, Loss: 72.65831756591797\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 103, Loss: 71.38794708251953\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 104, Loss: 70.08033752441406\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 105, Loss: 68.90855407714844\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 106, Loss: 67.67762756347656\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 107, Loss: 66.46713256835938\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 108, Loss: 65.26444244384766\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 109, Loss: 64.04718780517578\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 110, Loss: 62.92475891113281\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 111, Loss: 61.75179672241211\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 112, Loss: 60.67043685913086\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 113, Loss: 59.518714904785156\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 114, Loss: 58.4494514465332\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 115, Loss: 57.35446548461914\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 116, Loss: 56.28012466430664\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 117, Loss: 55.255855560302734\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 118, Loss: 54.22874069213867\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 119, Loss: 53.23716354370117\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 120, Loss: 52.27701187133789\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 121, Loss: 51.30961990356445\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 122, Loss: 50.40264892578125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 123, Loss: 49.49873352050781\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 124, Loss: 48.63178253173828\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 125, Loss: 47.72373580932617\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 126, Loss: 46.843109130859375\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 127, Loss: 45.97144317626953\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 128, Loss: 45.1539421081543\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 129, Loss: 44.35331344604492\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 130, Loss: 43.58383560180664\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 131, Loss: 42.8590202331543\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 132, Loss: 42.092803955078125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 133, Loss: 41.355133056640625\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 134, Loss: 40.529544830322266\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 135, Loss: 39.882301330566406\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 136, Loss: 39.32588577270508\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 137, Loss: 38.49338912963867\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 138, Loss: 37.97258377075195\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 139, Loss: 37.46438217163086\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 140, Loss: 36.63025665283203\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 141, Loss: 36.169376373291016\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 142, Loss: 35.33946990966797\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 143, Loss: 34.800323486328125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 144, Loss: 34.21947479248047\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 145, Loss: 33.54607391357422\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 146, Loss: 33.04350662231445\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 147, Loss: 32.43174362182617\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 148, Loss: 31.868898391723633\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 149, Loss: 31.360275268554688\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 150, Loss: 30.764545440673828\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 151, Loss: 30.2314453125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 152, Loss: 29.746034622192383\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 153, Loss: 29.242359161376953\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 154, Loss: 28.796772003173828\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 155, Loss: 28.27716636657715\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 156, Loss: 27.772560119628906\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 157, Loss: 27.322795867919922\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 158, Loss: 26.86190414428711\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 159, Loss: 26.423276901245117\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 160, Loss: 26.01631736755371\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 161, Loss: 25.579036712646484\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 162, Loss: 25.199562072753906\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 163, Loss: 24.76216697692871\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 164, Loss: 24.34266471862793\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 165, Loss: 23.930381774902344\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 166, Loss: 23.517879486083984\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 167, Loss: 23.176435470581055\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 168, Loss: 22.885295867919922\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 169, Loss: 22.472396850585938\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 170, Loss: 22.142189025878906\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 171, Loss: 21.720428466796875\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 172, Loss: 21.399690628051758\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 173, Loss: 21.01036262512207\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 174, Loss: 20.666728973388672\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 175, Loss: 20.333751678466797\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 176, Loss: 19.988359451293945\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 177, Loss: 19.66593360900879\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 178, Loss: 19.340412139892578\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 179, Loss: 19.047216415405273\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 180, Loss: 18.695159912109375\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 181, Loss: 18.41575813293457\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 182, Loss: 18.118677139282227\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 183, Loss: 17.830854415893555\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 184, Loss: 17.532176971435547\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 185, Loss: 17.279577255249023\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 186, Loss: 17.042404174804688\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 187, Loss: 16.785860061645508\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 188, Loss: 16.50421714782715\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 189, Loss: 16.300846099853516\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 190, Loss: 16.07366943359375\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 191, Loss: 15.922374725341797\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 192, Loss: 15.77094841003418\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 193, Loss: 15.44147777557373\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 194, Loss: 15.214373588562012\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 195, Loss: 14.977567672729492\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 196, Loss: 14.754707336425781\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 197, Loss: 14.518855094909668\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 198, Loss: 14.3389892578125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 199, Loss: 14.132500648498535\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Your code here: change the number of epochs to see how it effects training time and quality\n",
    "'''\n",
    "epochs = 200\n",
    "\n",
    "\n",
    "'''\n",
    "Training -- no need to touch the code below.\n",
    "'''\n",
    "torch.cuda.empty_cache()\n",
    "model.train()\n",
    "model.to(device)\n",
    "loss_records = []\n",
    "\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    # runs the model and calculates loss\n",
    "    loss = 0\n",
    "    for _, (enc_in, dec_in, dec_out) in enumerate(dataloader):\n",
    "        # enc_h_0.shape: [1(num_layers), 1(batch_size), 32(hidden_size)]\n",
    "        enc_h_0 = model.init_enc_hidden_GRU(batch_size, device)\n",
    "        # To Cuda Device if available\n",
    "        enc_in, dec_in = enc_in.to(device), dec_in.to(device)\n",
    "\n",
    "        pred = model(enc_in, enc_h_0, dec_in)\n",
    "\n",
    "        dec_out = dec_out.to(device)\n",
    "        for i in range(len(dec_out)): # dec_in.shape: [1(b), 40(out_maxlen)]\n",
    "            # pred[i].shape: [40(out_maxlen), 317(dec_n_class)]\n",
    "            # dec_out[i].shape: [40(out_maxlen)]\n",
    "            loss += criterion(pred[i], dec_out[i])\n",
    "\n",
    "    if (epoch) % 1 == 0:\n",
    "        print(f\"Epoch: {epoch}, Loss: {loss}\")\n",
    "\n",
    "    if (epoch) % 100 == 0:\n",
    "        loss_records.append(loss)\n",
    "\n",
    "    # runs the actual back propacation\n",
    "    optim.zero_grad()\n",
    "    loss.backward()\n",
    "    optim.step()\n",
    "    torch.save(model.state_dict(), \"seq2seq.pt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Let's check out our model's progress\n",
    "\n",
    "No need to change the code below, this will plot our loss over time. How do you think we can tweak our code to decrease loss even further?\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false,
    "id": "DCWlner5CkY-"
   },
   "outputs": [
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.switch_backend('agg')\n",
    "%matplotlib inline\n",
    "import matplotlib.ticker as ticker\n",
    "import numpy as np\n",
    "\n",
    "def showPlot(points): # Helper function for showing our plots\n",
    "    plt.figure()\n",
    "    fig, ax = plt.subplots()\n",
    "    loc = ticker.MultipleLocator(base=0.2)\n",
    "    ax.yaxis.set_major_locator(loc)\n",
    "    plt.plot(points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 720
    },
    "collapsed": false,
    "id": "WGjbNIopCkzd",
    "outputId": "dc2375cb-efe2-4756-dd01-309e4f056e1a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "execution_count": 62,
     "metadata": {
     },
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Locator attempting to generate 2753 ticks ([50.2, ..., 600.6]), which exceeds Locator.MAXTICKS (1000).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Locator attempting to generate 2753 ticks ([50.2, ..., 600.6]), which exceeds Locator.MAXTICKS (1000).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Locator attempting to generate 2753 ticks ([50.2, ..., 600.6]), which exceeds Locator.MAXTICKS (1000).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Locator attempting to generate 2753 ticks ([50.2, ..., 600.6]), which exceeds Locator.MAXTICKS (1000).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Locator attempting to generate 2753 ticks ([50.2, ..., 600.6]), which exceeds Locator.MAXTICKS (1000).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Locator attempting to generate 2753 ticks ([50.2, ..., 600.6]), which exceeds Locator.MAXTICKS (1000).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Locator attempting to generate 2753 ticks ([50.2, ..., 600.6]), which exceeds Locator.MAXTICKS (1000).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Locator attempting to generate 2753 ticks ([50.2, ..., 600.6]), which exceeds Locator.MAXTICKS (1000).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Locator attempting to generate 2753 ticks ([50.2, ..., 600.6]), which exceeds Locator.MAXTICKS (1000).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Locator attempting to generate 2753 ticks ([50.2, ..., 600.6]), which exceeds Locator.MAXTICKS (1000).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Locator attempting to generate 2753 ticks ([50.2, ..., 600.6]), which exceeds Locator.MAXTICKS (1000).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Locator attempting to generate 2753 ticks ([50.2, ..., 600.6]), which exceeds Locator.MAXTICKS (1000).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Locator attempting to generate 2753 ticks ([50.2, ..., 600.6]), which exceeds Locator.MAXTICKS (1000).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Locator attempting to generate 2753 ticks ([50.2, ..., 600.6]), which exceeds Locator.MAXTICKS (1000).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Locator attempting to generate 2753 ticks ([50.2, ..., 600.6]), which exceeds Locator.MAXTICKS (1000).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Locator attempting to generate 2753 ticks ([50.2, ..., 600.6]), which exceeds Locator.MAXTICKS (1000).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Locator attempting to generate 2753 ticks ([50.2, ..., 600.6]), which exceeds Locator.MAXTICKS (1000).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Locator attempting to generate 2753 ticks ([50.2, ..., 600.6]), which exceeds Locator.MAXTICKS (1000).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Locator attempting to generate 2753 ticks ([50.2, ..., 600.6]), which exceeds Locator.MAXTICKS (1000).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Locator attempting to generate 2753 ticks ([50.2, ..., 600.6]), which exceeds Locator.MAXTICKS (1000).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Locator attempting to generate 2753 ticks ([50.2, ..., 600.6]), which exceeds Locator.MAXTICKS (1000).\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "execution_count": 62,
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "showPlot([loss.cpu().item() for loss in loss_records])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "<h1>Code for Translating with our Model</h1>\n",
    "This is where the Seq2Seq happens after the model is trained.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": false,
    "id": "XHs9IRJK8usV"
   },
   "outputs": [
   ],
   "source": [
    "'''\n",
    "No need to touch this code: \n",
    "'''\n",
    "\n",
    "def translate(eng_sent, model, device):\n",
    "    # set up the inputs and variables\n",
    "    model.eval()\n",
    "    model.to(device)\n",
    "    eng_sent = tk.tokenize(eng_sent.lower()) + [\"<EOS>\"]\n",
    "    eng_sent = input_tokenizer.transform(eng_sent, max_len=in_maxlen, pad_first=False)\n",
    "    dec_in = ([\"<SOS>\"] + [\"<PAD>\"]*out_maxlen)[:out_maxlen]\n",
    "    dec_in = output_tokenizer.transform(dec_in, max_len=out_maxlen, pad_first=False)\n",
    "\n",
    "    enc_h_0 = model.init_enc_hidden_GRU(batch_size, device)\n",
    "    eng_sent, dec_in = torch.LongTensor(eng_sent), torch.LongTensor(dec_in)\n",
    "\n",
    "    eng_sent = eng_sent.unsqueeze(0)\n",
    "    dec_in = dec_in.unsqueeze(0)\n",
    "    eng_sent, dec_in = eng_sent.to(device), dec_in.to(device)\n",
    "\n",
    "    # run the model\n",
    "    with torch.no_grad():\n",
    "        # eng_sent: [1(b), 26(in_maxlen)]\n",
    "        embedded_X = model.embed_enc(eng_sent)\n",
    "        # embedded_X: [26(in_maxlen), 1(b), 64(d_model)] <- [1(b), 26(in_maxlen), 64(d_model)]\n",
    "        embedded_X = embedded_X.permute(1, 0, 2)\n",
    "        _, memory = model.encoder(embedded_X, enc_h_0)\n",
    "        pred_loc = 0\n",
    "        for i in range(out_maxlen-1):\n",
    "            embedded_Y = model.embed_dec(dec_in)\n",
    "            embedded_Y = embedded_Y.permute(1, 0, 2)\n",
    "            outputs, _ = model.decoder(embedded_Y, memory)\n",
    "            outputs = outputs.permute(1, 0, 2)\n",
    "            pred = model.fc(outputs)\n",
    "            pred = pred[0][pred_loc].topk(1)[1].item()\n",
    "            pred_loc += 1\n",
    "            if pred == 2:\n",
    "                dec_in[0][pred_loc] = pred\n",
    "                break\n",
    "            else:\n",
    "                dec_in[0][pred_loc] = pred\n",
    "    return dec_in"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "id": "kG_fTQzoBsMu"
   },
   "source": [
    "# Using our Model in Practice\n",
    "Check out these examples below. This is how you can translate sequences!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": false,
    "id": "fh0-iZdvBUFF",
    "outputId": "f42cb9ed-a961-4d0f-c94c-6be4fb8d6656",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now's the time to decide whether you really want to get married or not. -> \n",
      "现在是你<UNK>定是不是真要结婚的时候。\n",
      "To the man who only has a hammer in the toolkit, every problem looks like a nail. -> \n",
      "对工<UNK>箱里只有一把<UNK><UNK>的人来说，所有的问<UNK>都像<UNK>子。\n",
      "The good thing about this electronic dictionary is that it's easy to carry. -> \n",
      "这电子<UNK>典的好处就是便于<UNK><UNK>。\n",
      "Manholes are round because that way they won't accidentally fall through the hole. -> \n",
      "人孔是<UNK>的，因為這<UNK>人孔<UNK>就不會意外地<UNK><UNK><UNK><UNK>。\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Whoever said money can't buy happiness simply didn't know where to go shopping. -> \n",
      "那些说钱不能买来幸福的人，只是不知道上哪里去买而已。\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "eng_sents = random.sample(input_texts, 5)\n",
    "for sent in eng_sents:\n",
    "  translated = translate(sent, model, torch.device(\"cpu\"))\n",
    "  translated_sent = output_tokenizer.inverse_transform(translated[0], is_tensor=True)\n",
    "  translated_sent = \"\".join([word for word in translated_sent if word != \"<SOS>\" and word != \"<EOS>\"and word != \"<PAD>\"])\n",
    "  print(f\"{sent} -> \\n{translated_sent}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Your turn!\n",
    "\n",
    "Can you use the code in the cell above to translate custom sentences? \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "cocalc": {
     "outputs": {
      "0": {
       "name": "input",
       "opts": {
        "password": false,
        "prompt": "Ok. You dont know chinese? fine... here:"
       },
       "output_type": "stream"
      }
     }
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "Ok. You dont know chinese? fine... here: "
    }
   ],
   "source": [
    "'''\n",
    "Your code here: translate custom sentences using the code above. Hint: You won't need a for loop!\n",
    "'''\n",
    "\n",
    "engeng_sents = input(\"Ok. You dont know chinese? fine... here:\")\n",
    "translated = translate(engeng_sents, model, torch.device(\"cpu\"))\n",
    "translated_sent = output_tokenizer.inverse_transform(translated[0], is_tensor=True)\n",
    "translated_sent = \"\".join([word for word in translated_sent if word != \"<SOS>\" and word != \"<EOS>\"and word !=\"<PAD>\"])\n",
    "print(translated_sent)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
   ],
   "name": "Seq2Seq en-cn.ipynb",
   "provenance": [
   ]
  },
  "interpreter": {
   "hash": "335ee12212264728feb72f243af72c5a8ea26c832f07e1f651ce9e17c7ceae23"
  },
  "kernelspec": {
   "display_name": "Python (nlp_env)",
   "language": "python",
   "metadata": {
    "debugger": true
   },
   "name": "nlp_env",
   "resource_dir": "/projects/b9e0cba5-06d0-4604-824f-bbb5d6223324/.local/share/jupyter/kernels/nlp_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}