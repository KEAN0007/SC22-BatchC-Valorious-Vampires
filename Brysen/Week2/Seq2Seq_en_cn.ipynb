{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# The Task at Hand\n",
    "\n",
    "Have you ever wondered if computers could translate languages? Did you think google translate or duolingo worked because they memorized answers? \n",
    "\n",
    "The type of problem that translation solves is sequence to sequence. For instance, we could convert an english input sequence to a german output sequence. \n",
    "\n",
    "In this activity, we will create an english -> chinese translator and apply what we've been learning about LSTMs & RNNs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Preparing the data\n",
    "We need to import our packages and data to learn a little bit about the problem at hand."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "id": "PS0kPzE04YFO"
   },
   "outputs": [
   ],
   "source": [
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "from nltk.tokenize import WordPunctTokenizer\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn.functional as F\n",
    "import pandas as pd\n",
    "import torch\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "from Word2Sequence import Word2Sequence\n",
    "from Dataset import Dataset\n",
    "from Seq2Seq import Seq2Seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
    "# read small_en-cn.txt file\n",
    "data_path = './eng-chin.txt'\n",
    "df = pd.read_table(data_path,header=None).iloc[:,:]\n",
    "df = df.drop([2],axis=1)\n",
    "df.columns=['english','chinese']\n",
    "\n",
    "input_texts = df.english.values.tolist() #this will be all of the english sentences\n",
    "target_texts = df.chinese.values.tolist() #this will be all of the chinese sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I thought that we had found the perfect hiding place, but the police found us. 我以为我们发现了绝妙的藏身之处，但警察找到了我们。\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Your code here: Try printing some english and chinese sentences from their lists input_texts and target_texts!\n",
    "'''\n",
    "import random\n",
    "rn = random.randint(0, 98)\n",
    "print(input_texts[rn], target_texts[rn])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "id": "cPXhq9PO4dOC"
   },
   "outputs": [
   ],
   "source": [
    "#read in our model object. Tokenize our data\n",
    "tk = WordPunctTokenizer()\n",
    "english = [tk.tokenize(sentence.lower()) for sentence in input_texts]\n",
    "chinese = [[x for x in sentence] for sentence in target_texts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max_english_length: 25\n",
      "max_chinese_length: 39\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Your code here: Explore this data. Can you calculate the maximum length of a sequence in each dataset english and chinese?\n",
    "'''\n",
    "# calculate max_len of any sequence in 'english' list and save it to a variable called max_english_length\n",
    "max_english_length = 0\n",
    "for sentence in english:\n",
    "    if len(sentence) > max_english_length:\n",
    "        max_english_length = len(sentence)\n",
    "\n",
    "# calculate max_len of any sequence in 'chinese' list and save it to a variable called max_chinese_length\n",
    "max_chinese_length = 0\n",
    "for sentence in chinese:\n",
    "    if len(sentence) > max_chinese_length:\n",
    "        max_chinese_length = len(sentence)\n",
    "\n",
    "print('max_english_length:', max_english_length)\n",
    "print('max_chinese_length:', max_chinese_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": false,
    "id": "ZzoUqCrq4fWj",
    "outputId": "4290ee15-457e-44d7-f083-f12a2e5d78a2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total english words: 199\n",
      "total chinese words: 317\n"
     ]
    }
   ],
   "source": [
    "input_tokenizer = Word2Sequence()\n",
    "for words in english:\n",
    "    input_tokenizer.fit(words)\n",
    "input_tokenizer.build_vocab(min=1, max_features=None) #inpu\n",
    "\n",
    "output_tokenizer = Word2Sequence()\n",
    "for words in chinese:\n",
    "    output_tokenizer.fit(words)\n",
    "output_tokenizer.build_vocab(min=1, max_features=None)\n",
    "\n",
    "'''\n",
    "Your code here: print the total english words in your input tokenizer and total chinese words in your output tokenizer below!\n",
    "'''\n",
    "print('total english words:', input_tokenizer.__len__())\n",
    "print('total chinese words:', output_tokenizer.__len__())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "<h1>Creating the model</h1>\n",
    "\n",
    "![image.png](data:image/png;base64,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)\n",
    "\n",
    "NOTE: For Structure of Encoder Inputs, they can all be either (assume all have same maxlen): \n",
    "1. \\<SOS>, word1, word2, word3, ..., \\<EOS>\n",
    "2. word1, word2, word3, ..., \\<EOS> \n",
    "3. word1, word2, word3, ...\n",
    "\n",
    "NOTE: But Decoder In and Out structures should always look like this (assume all have same maxlen):\n",
    "- Decoder Input: \\<SOS>, word1, word2, word3, ...\n",
    "- Decoder Output: word1, word2, word3, ..., \\<EOS>  \n",
    "\n",
    "This means that our input and ouput max length should be one more than the sequence's max length.\n",
    "\n",
    "WHY? Data Structure:\n",
    "- 1. Encoder Input: [word1, word2, ... + <EOS>]\n",
    "- 2. Decoder Input: [<SOS> + word1, word2, ...]\n",
    "- 3. Decoder Output:[word1, word2, ... + <EOS>]\n",
    "    \n",
    "nn docs - https://pytorch.org/docs/stable/nn.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "id": "qm_Qhnlk49Rn"
   },
   "outputs": [
   ],
   "source": [
    "# Seq2Seq Parameters\n",
    "in_maxlen = max_english_length + 1 # 25 + 1(<EOS> token)\n",
    "out_maxlen = max_chinese_length + 1 # 39 + 1(<EOS> token or <SOS> token)\n",
    "n_hidden = 32 # number of \"neurons\" per layer\n",
    "d_model = 64 # number of embedding dimensions to represent each word\n",
    "enc_n_class = len(input_tokenizer.dict) # OR... vocab size of englisth -> 199\n",
    "dec_n_class = len(output_tokenizer.dict) # OR... vocab size of chinese -> 317\n",
    "batch_size = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
    "eng_maxlen = max_english_length + 1 # 25 + 1(<EOS> token)\n",
    "chin_maxlen = max_chinese_length + 1  # 39 + 1(<EOS> token or <SOS> token)\n",
    "batch_size = 1 \n",
    "\n",
    "# Setup the Dataset.\n",
    "dataset = Dataset(\n",
    "    X = english,\n",
    "    Y = chinese,\n",
    "    in_tknz = input_tokenizer, out_tknz = output_tokenizer,\n",
    "    in_maxlen = eng_maxlen, out_maxlen = chin_maxlen\n",
    ")\n",
    "\n",
    "'''\n",
    "The following are helper functions to help pytorch. You won't need to know this much.\n",
    "'''\n",
    "# NOTE: collate_fn preprocesses your input from PyTorch Dataset above during PyTorch DataLoader\n",
    "def collate_fn(batch):\n",
    "    '''\n",
    "    param batch: ([enc_in, dec_in, dec_out]， [enc_in, dec_in, dec_out], output of getitem...)\n",
    "    '''\n",
    "    # unpack values\n",
    "    enc_in, dec_in, dec_out = list(zip(*batch))\n",
    "    # Return tensor type\n",
    "    return torch.LongTensor(enc_in), torch.LongTensor(dec_in), torch.LongTensor(dec_out)\n",
    "\n",
    "def get_dataloader(dataset, batch_size, shuffle=True, drop_last=True, collate_fn=collate_fn):\n",
    "    '''\n",
    "    Returns a way to access and use the data\n",
    "    '''\n",
    "    dataloader = DataLoader(dataset=dataset,\n",
    "                            batch_size=batch_size,\n",
    "                            shuffle=shuffle,\n",
    "                            drop_last=drop_last,\n",
    "                            collate_fn=collate_fn)\n",
    "    return dataloader\n",
    "# Get PyTorch DataLoader\n",
    "dataloader = get_dataloader(dataset, batch_size)\n",
    "dataloader = get_dataloader(dataset, batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": false,
    "id": "oVVbVP7l5AJg",
    "outputId": "e28da9fa-5fa2-4fbd-b4d3-49de9999475b"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/projects/b9e0cba5-06d0-4604-824f-bbb5d6223324/.local/lib/python3.8/site-packages/torch/nn/modules/rnn.py:62: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.3 and num_layers=1\n",
      "  warnings.warn(\"dropout option adds dropout after all but last \"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Seq2Seq(\n",
       "  (encoder): GRU(64, 32, dropout=0.3)\n",
       "  (decoder): GRU(64, 32, dropout=0.3)\n",
       "  (embed_enc): Embedding(199, 64)\n",
       "  (embed_dec): Embedding(317, 64)\n",
       "  (fc): Linear(in_features=32, out_features=317, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 15,
     "metadata": {
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Seq2Seq(\n",
    "    in_maxlen = in_maxlen,\n",
    "    out_maxlen = out_maxlen,\n",
    "    n_hidden = n_hidden,\n",
    "    enc_n_class = len(input_tokenizer.dict),\n",
    "    dec_n_class = len(output_tokenizer.dict),\n",
    "    d_model = d_model,\n",
    "    num_layers = 1,\n",
    ")\n",
    "model.to(device)\n",
    "# # If you have saved a model before\n",
    "# model.load_state_dict(torch.load(\"seq2seq.pt\", map_location=device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false,
    "id": "PtNvjmBo5A8W"
   },
   "outputs": [
   ],
   "source": [
    "# Define Loss and Optimizer -- these are ways we define performance for our model. If you're curious: https://pytorch.org/tutorials/beginner/basics/optimization_tutorial.html\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optim = torch.optim.Adam(model.parameters(), lr=1e-2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "id": "wVpmLnAtBLEV"
   },
   "source": [
    "<h1>Training our model</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": false,
    "id": "PTSlF8fk5QpG",
    "outputId": "3eb0df28-80b9-452b-e9b5-5c7ffff27c98"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, Loss: 509.718017578125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 10, Loss: 264.8349914550781\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 20, Loss: 231.07916259765625\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 30, Loss: 208.9425506591797\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 40, Loss: 185.1838836669922\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 50, Loss: 160.76028442382812\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 60, Loss: 137.586669921875\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 70, Loss: 116.52574920654297\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 80, Loss: 98.19603729248047\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 90, Loss: 82.4125747680664\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 100, Loss: 69.05858612060547\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 110, Loss: 57.92717742919922\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 120, Loss: 48.682456970214844\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 130, Loss: 41.15633773803711\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 140, Loss: 34.785518646240234\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 150, Loss: 29.802488327026367\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 160, Loss: 25.404434204101562\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 170, Loss: 21.672164916992188\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 180, Loss: 20.304332733154297\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 190, Loss: 16.60958480834961\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 200, Loss: 14.172014236450195\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 210, Loss: 12.277118682861328\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 220, Loss: 10.744781494140625\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 230, Loss: 9.579378128051758\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 240, Loss: 8.83117389678955\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 250, Loss: 7.687771797180176\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Your code here: change the number of epochs to see how it effects training time and quality\n",
    "'''\n",
    "epochs = 256\n",
    "\n",
    "'''\n",
    "Training -- no need to touch the code below.\n",
    "'''\n",
    "torch.cuda.empty_cache()\n",
    "model.train()\n",
    "model.to(device)\n",
    "loss_records = []\n",
    "\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    # runs the model and calculates loss\n",
    "    loss = 0\n",
    "    for _, (enc_in, dec_in, dec_out) in enumerate(dataloader):\n",
    "        # enc_h_0.shape: [1(num_layers), 1(batch_size), 32(hidden_size)]\n",
    "        enc_h_0 = model.init_enc_hidden_GRU(batch_size, device)\n",
    "        # To Cuda Device if available\n",
    "        enc_in, dec_in = enc_in.to(device), dec_in.to(device)\n",
    "\n",
    "        pred = model(enc_in, enc_h_0, dec_in)\n",
    "\n",
    "        dec_out = dec_out.to(device)\n",
    "        for i in range(len(dec_out)): # dec_in.shape: [1(b), 40(out_maxlen)]\n",
    "            # pred[i].shape: [40(out_maxlen), 317(dec_n_class)]\n",
    "            # dec_out[i].shape: [40(out_maxlen)]\n",
    "            loss += criterion(pred[i], dec_out[i])\n",
    "\n",
    "    if (epoch) % 1 == 0:\n",
    "        print(f\"Epoch: {epoch}, Loss: {loss}\")\n",
    "\n",
    "    if (epoch) % 100 == 0:\n",
    "        loss_records.append(loss)\n",
    "\n",
    "    # runs the actual back propacation\n",
    "    optim.zero_grad()\n",
    "    loss.backward()\n",
    "    optim.step()\n",
    "    torch.save(model.state_dict(), \"seq2seq.pt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Let's check out our model's progress\n",
    "No need to change the code below, this will plot our loss over time. How do you think we can tweak our code to decrease loss even further?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false,
    "id": "DCWlner5CkY-"
   },
   "outputs": [
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.switch_backend('agg')\n",
    "%matplotlib inline\n",
    "import matplotlib.ticker as ticker\n",
    "import numpy as np\n",
    "\n",
    "def showPlot(points): # Helper function for showing our plots\n",
    "    plt.figure()\n",
    "    fig, ax = plt.subplots()\n",
    "    loc = ticker.MultipleLocator(base=0.2)\n",
    "    ax.yaxis.set_major_locator(loc)\n",
    "    plt.plot(points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 720
    },
    "collapsed": false,
    "id": "WGjbNIopCkzd",
    "outputId": "dc2375cb-efe2-4756-dd01-309e4f056e1a",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "execution_count": 20,
     "metadata": {
     },
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Locator attempting to generate 2728 ticks ([-10.8, ..., 534.6]), which exceeds Locator.MAXTICKS (1000).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Locator attempting to generate 2728 ticks ([-10.8, ..., 534.6]), which exceeds Locator.MAXTICKS (1000).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Locator attempting to generate 2728 ticks ([-10.8, ..., 534.6]), which exceeds Locator.MAXTICKS (1000).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Locator attempting to generate 2728 ticks ([-10.8, ..., 534.6]), which exceeds Locator.MAXTICKS (1000).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Locator attempting to generate 2728 ticks ([-10.8, ..., 534.6]), which exceeds Locator.MAXTICKS (1000).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Locator attempting to generate 2728 ticks ([-10.8, ..., 534.6]), which exceeds Locator.MAXTICKS (1000).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Locator attempting to generate 2728 ticks ([-10.8, ..., 534.6]), which exceeds Locator.MAXTICKS (1000).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Locator attempting to generate 2728 ticks ([-10.8, ..., 534.6]), which exceeds Locator.MAXTICKS (1000).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Locator attempting to generate 2728 ticks ([-10.8, ..., 534.6]), which exceeds Locator.MAXTICKS (1000).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Locator attempting to generate 2728 ticks ([-10.8, ..., 534.6]), which exceeds Locator.MAXTICKS (1000).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Locator attempting to generate 2728 ticks ([-10.8, ..., 534.6]), which exceeds Locator.MAXTICKS (1000).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Locator attempting to generate 2728 ticks ([-10.8, ..., 534.6]), which exceeds Locator.MAXTICKS (1000).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Locator attempting to generate 2728 ticks ([-10.8, ..., 534.6]), which exceeds Locator.MAXTICKS (1000).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Locator attempting to generate 2728 ticks ([-10.8, ..., 534.6]), which exceeds Locator.MAXTICKS (1000).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Locator attempting to generate 2728 ticks ([-10.8, ..., 534.6]), which exceeds Locator.MAXTICKS (1000).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Locator attempting to generate 2728 ticks ([-10.8, ..., 534.6]), which exceeds Locator.MAXTICKS (1000).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Locator attempting to generate 2728 ticks ([-10.8, ..., 534.6]), which exceeds Locator.MAXTICKS (1000).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Locator attempting to generate 2728 ticks ([-10.8, ..., 534.6]), which exceeds Locator.MAXTICKS (1000).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Locator attempting to generate 2728 ticks ([-10.8, ..., 534.6]), which exceeds Locator.MAXTICKS (1000).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Locator attempting to generate 2728 ticks ([-10.8, ..., 534.6]), which exceeds Locator.MAXTICKS (1000).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Locator attempting to generate 2728 ticks ([-10.8, ..., 534.6]), which exceeds Locator.MAXTICKS (1000).\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "execution_count": 20,
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "showPlot([loss.cpu().item() for loss in loss_records])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "<h1>Code for Translating with our Model</h1>\n",
    "This is where the Seq2Seq happens after the model is trained.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false,
    "id": "XHs9IRJK8usV"
   },
   "outputs": [
   ],
   "source": [
    "'''\n",
    "No need to touch this code: \n",
    "'''\n",
    "\n",
    "def translate(eng_sent, model, device):\n",
    "    # set up the inputs and variables\n",
    "    model.eval()\n",
    "    model.to(device)\n",
    "    eng_sent = tk.tokenize(eng_sent.lower()) + [\"<EOS>\"]\n",
    "    eng_sent = input_tokenizer.transform(eng_sent, max_len=in_maxlen, pad_first=False)\n",
    "    dec_in = ([\"<SOS>\"] + [\"<PAD>\"]*out_maxlen)[:out_maxlen]\n",
    "    dec_in = output_tokenizer.transform(dec_in, max_len=out_maxlen, pad_first=False)\n",
    "    \n",
    "    enc_h_0 = model.init_enc_hidden_GRU(batch_size, device)\n",
    "    eng_sent, dec_in = torch.LongTensor(eng_sent), torch.LongTensor(dec_in)\n",
    "\n",
    "    eng_sent = eng_sent.unsqueeze(0)\n",
    "    dec_in = dec_in.unsqueeze(0)\n",
    "    eng_sent, dec_in = eng_sent.to(device), dec_in.to(device)\n",
    "\n",
    "    # run the model\n",
    "    with torch.no_grad():\n",
    "        # eng_sent: [1(b), 26(in_maxlen)]\n",
    "        embedded_X = model.embed_enc(eng_sent)\n",
    "        # embedded_X: [26(in_maxlen), 1(b), 64(d_model)] <- [1(b), 26(in_maxlen), 64(d_model)]\n",
    "        embedded_X = embedded_X.permute(1, 0, 2)\n",
    "        _, memory = model.encoder(embedded_X, enc_h_0)\n",
    "        pred_loc = 0\n",
    "        for i in range(out_maxlen-1):\n",
    "            embedded_Y = model.embed_dec(dec_in)\n",
    "            embedded_Y = embedded_Y.permute(1, 0, 2)\n",
    "            outputs, _ = model.decoder(embedded_Y, memory)\n",
    "            outputs = outputs.permute(1, 0, 2)\n",
    "            pred = model.fc(outputs)\n",
    "            pred = pred[0][pred_loc].topk(1)[1].item()\n",
    "            pred_loc += 1\n",
    "            if pred == 2:\n",
    "                dec_in[0][pred_loc] = pred\n",
    "                break\n",
    "            else:\n",
    "                dec_in[0][pred_loc] = pred\n",
    "    return dec_in"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "id": "kG_fTQzoBsMu"
   },
   "source": [
    "# Using our Model in Practice\n",
    "Check out these examples below. This is how you can translate sequences!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": false,
    "id": "fh0-iZdvBUFF",
    "outputId": "f42cb9ed-a961-4d0f-c94c-6be4fb8d6656",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We apologize for the delay and regret any inconvenience it may have caused. -> \n",
      "我们对这次的延<UNK>表示<UNK><UNK>，并对可能<UNK>成的不便表示<UNK><UNK>。\n",
      "You seem to be prejudiced against ideas that come from foreign countries. -> \n",
      "你<UNK><UNK>我吃完這個<UNK>我就會<UNK>得<UNK>服一<UNK>。\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In the U.S., most people can vote when they reach eighteen years of age. -> \n",
      "在美国，大多数人能在十八岁后<UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK>。\n",
      "Tom always speaks in such a low voice that I can barely understand what he says. -> \n",
      "汤姆总是说话<UNK>音<UNK><UNK>，我几乎听不懂他在说什么。\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The world is just like a book, and every step you take is like turning a page. -> \n",
      "世界就像是一本书，<UNK>一<UNK>等于<UNK>了一<UNK>。\n",
      "You shouldn't share too much private information on the social networks. -> \n",
      "你不<UNK>该在社交<UNK><UNK>上分<UNK><UNK>多<UNK>人信<UNK>。\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You're much less likely to get a good position if you don't speak English. -> \n",
      "如果你不会说英语，你就很难得到一个好的<UNK>位。\n",
      "If a sick person folds one thousand paper cranes, her wish will come true. -> \n",
      "如果一個<UNK>人<UNK>一<UNK><UNK><UNK><UNK>, 她的<UNK>望就會成真。\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "While I was reading in bed last night, I fell asleep with the light on. -> \n",
      "我昨晚在<UNK>上看书的时候点着<UNK>就<UNK>了。\n",
      "A person views things differently according to whether they are rich or poor. -> \n",
      "每一個人對事情的看法不同是<UNK>據他們是富有<UNK>是貧窮。\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Does any other country fan the flames of patriotism as much as America? -> \n",
      "有没有一个国家比美国更提<UNK>爱国<UNK><UNK>？\n",
      "After he had graduated from the university, he taught English for two years. -> \n",
      "<UNK>他大學<UNK>業以後, 他教了<UNK>年的英語。\n",
      "She visits the dentist on a regular basis, so she seldom gets toothaches. -> \n",
      "她定<UNK>去看牙<UNK>，所以她很少牙<UNK>。\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I learned to drive a car when I was eighteen and got a driver's license. -> \n",
      "我十八歲時，學了開車、考到了駕照。\n",
      "By the way, did you find the umbrella you said you'd lost the other day? -> \n",
      "对了，前些时间你说<UNK>不见了，现在找到了吗？\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I don't have a lot of work, but it's enough to keep me in the office this week. -> \n",
      "其<UNK>我工作并不多，但足以让我这周在<UNK>公<UNK>里<UNK>着了。\n",
      "The ages of the two children put together was equivalent to that of their father. -> \n",
      "<UNK><UNK>写的人口。\n",
      "I returned the books I borrowed from the library, and I borrowed some new ones. -> \n",
      "我还了从图书馆借的书，<UNK>借了些新的。\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I learned to drive a car and got a driver's license when I was eighteen. -> \n",
      "我十八歲時，學了開車、考到了駕照。\n",
      "Three out of four Americans believe in the existence of paranormal phenomena. -> \n",
      "<UNK>分之<UNK>的美国人相信存在<UNK>自然现<UNK>。\n",
      "It's hard to believe that Tom wasn't aware that Mary was in love with him. -> \n",
      "真难相信汤姆不知道玛丽爱他。\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rather than cutting down on cigarettes, why don't you just give them up? -> \n",
      "比起少<UNK>菸，你何不直接把菸<UNK>了？\n",
      "We were talking about something at that time, but I don't remember what. -> \n",
      "我们那时在<UNK>论事情，但我不记得是什么了。\n",
      "Kindness is the language which the deaf can hear and the blind can see. -> \n",
      "<UNK>良是<UNK>子能<UNK><UNK>人能看的語言。\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "If it looks like an apple and it tastes like an apple, it's probably an apple. -> \n",
      "如果看起来像个苹果而且吃起来也像苹果的话，可能就是苹果。\n",
      "Being a good conversationalist does not just mean being a good speaker of English. -> \n",
      "作為一個良好的交<UNK>者，<UNK>不只意<UNK><UNK>作一個英語說得好的說話者。\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "English has now become the common language of several nations in the world. -> \n",
      "英语现已成为世界上<UNK>多国家的通用语言了。\n",
      "Tom can write almost like a native speaker, but his pronunciation is terrible. -> \n",
      "<UNK><UNK><UNK>写作可以写的像本国人一<UNK>，可是他的发音很<UNK><UNK>才<UNK><UNK>。\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "eng_sents = random.sample(input_texts, 28)\n",
    "for sent in eng_sents:\n",
    "  translated = translate(sent, model, torch.device(\"cpu\"))\n",
    "  translated_sent = output_tokenizer.inverse_transform(translated[0], is_tensor=True)\n",
    "  translated_sent = \"\".join([word for word in translated_sent if word != \"<SOS>\" and word != \"<EOS>\"and word != \"<PAD>\"])\n",
    "  print(f\"{sent} -> \\n{translated_sent}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Your turn!\n",
    "Can you use the code in the cell above to translate custom sentences? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "translate custom sentences using the code above -> \n",
      "我们在<UNK>上看书的时候点着<UNK>就<UNK>了。\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Your code here: translate custom sentences using the code above. Hint: You won't need a for loop!\n",
    "'''\n",
    "translated = translate(\"translate custom sentences using the code above\", model, torch.device(\"cpu\"))\n",
    "translated_sent = output_tokenizer.inverse_transform(translated[0], is_tensor=True)\n",
    "translated_sent = \"\".join([word for word in translated_sent if word != \"<SOS>\" and word != \"<EOS>\"and word != \"<PAD>\"])\n",
    "print(f\"translate custom sentences using the code above -> \\n{translated_sent}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
   ],
   "name": "Seq2Seq en-cn.ipynb",
   "provenance": [
   ]
  },
  "interpreter": {
   "hash": "335ee12212264728feb72f243af72c5a8ea26c832f07e1f651ce9e17c7ceae23"
  },
  "kernelspec": {
   "display_name": "Python (nlp_env)",
   "language": "python",
   "metadata": {
    "debugger": true
   },
   "name": "nlp_env",
   "resource_dir": "/projects/b9e0cba5-06d0-4604-824f-bbb5d6223324/.local/share/jupyter/kernels/nlp_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}